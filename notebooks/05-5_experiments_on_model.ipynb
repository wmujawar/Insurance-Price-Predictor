{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous experiments, we found that the StackingRegressor gave us pretty solid results, with a Train $R^2$ score of 91.33% and a Test $R^2$ score of 90.77% on the raw data (the accuracy wasn't as good when we used the processed data with feature engineering). In this notebook, weâ€™re going to try some new experiments to see if changing the final estimator in the StackingRegressor can help us get even better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from src.utils import r2_and_adjusted_r2_score as score, root_mean_squared_error as rmse\n",
    "from src.mlflow_util import setup_mlflow_experiment as setup_exp\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = os.path.join(parent_dir, 'data', 'raw')\n",
    "df = pd.read_csv(os.path.join(raw_data_dir, 'insurance.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('file:///Users/wasimmujawar/Desktop/Case '\n",
       " 'Study/Insaurance/mlruns/116828091641320024'), creation_time=1735710435805, experiment_id='116828091641320024', last_update_time=1735710435805, lifecycle_stage='active', name='Experiments Age Stratified on Raw Data', tags={'mlflow.note.content': 'The goal is to predict the PremiumPrice based on the '\n",
       "                        'given features.\\n'\n",
       "                        'Data is splitted using the Age feature to ensure that '\n",
       "                        'the distribution of Age is similar in both train and '\n",
       "                        'test sets.\\n'\n",
       "                        'There are no engineered features in this '\n",
       "                        'experiment.\\n'}>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = 'Experiments Age Stratified on Raw Data'\n",
    "exp_description = '''The goal is to predict the PremiumPrice based on the given features.\n",
    "Data is splitted using the Age feature to ensure that the distribution of Age is similar in both train and test sets.\n",
    "There are no engineered features in this experiment.\n",
    "'''\n",
    "\n",
    "experiment = setup_exp(exp_name, exp_description)\n",
    "\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "mlflow.set_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [18, 25, 40, 55, np.inf]\n",
    "age_labels = ['Young Adult', 'Adult', \n",
    "              'Middle Aged Adults', 'Senior']\n",
    "\n",
    "age_category = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['PremiumPrice']), df['PremiumPrice'],\n",
    "                                                    stratify=age_category, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['Age', 'Height', 'Weight']\n",
    "binary_columns = ['Diabetes', 'BloodPressureProblems', 'AnyTransplants', 'AnyChronicDiseases', 'KnownAllergies', 'HistoryOfCancerInFamily', 'NumberOfMajorSurgeries']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scaler', StandardScaler(), numeric_columns),\n",
    "    ('passthrough', 'passthrough', binary_columns)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = LinearRegression()\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with Linear Regression as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with Decision Tree as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = Ridge()\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with Ridge as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = Ridge(alpha=0.5)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with Ridge (alpha=0.5) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = Lasso()\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with Lasso as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = ElasticNet(max_iter=5000)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with ElasticNet as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = xgb.XGBRegressor(max_depth=4, n_estimators=80)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with XGBRegressor (depth=4) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = RandomForestRegressor(max_depth=4, n_estimators=120)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with RandomForestRegressor (depth=4, est=120) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = RandomForestRegressor(max_depth=6, n_estimators=120)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with RandomForestRegressor (depth=6, est=120) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = RandomForestRegressor(max_depth=6, n_estimators=150)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with RandomForestRegressor (depth=6, est=150) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = ElasticNet(alpha=0.5, l1_ratio=0.3, max_iter=5000)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with ElasticNet(alpha=0.5, l1_ratio=0.3) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = ElasticNet(alpha=0.7, l1_ratio=0.6, max_iter=5000)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with ElasticNet(alpha=0.7, l1_ratio=0.6) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = ElasticNet(alpha=0.7, l1_ratio=0.3, max_iter=5000)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with ElasticNet(alpha=0.7, l1_ratio=0.3) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = ElasticNet(alpha=0.8, l1_ratio=0.2, max_iter=5000)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with ElasticNet(alpha=0.8, l1_ratio=0.2) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = ElasticNet(alpha=0.9, l1_ratio=0.2, max_iter=5000)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with ElasticNet(alpha=0.9, l1_ratio=0.2) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=80, max_depth=5, learning_rate=0.3, loss='huber')),\n",
    "    ('gb3', GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.2, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=6, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=110, max_depth=6, n_jobs=-1)),\n",
    "    ('xg', xgb.XGBRegressor(max_depth=4, n_estimators=80, learning_rate=0.05, reg_alpha=0.7, reg_lambda=0.1))\n",
    "]\n",
    "\n",
    "final_estimator = ElasticNet(alpha=0.8, l1_ratio=0.3, max_iter=5000)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Stacking Regressor with ElasticNet(alpha=0.8, l1_ratio=0.3) as Final Estimator\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', StackingRegressor(estimators=base_learner, final_estimator=final_estimator))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    rmse_train = rmse(y_train, y_train_pred)\n",
    "    rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, y_train_pred)\n",
    "\n",
    "    r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "    r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    mlflow.set_tag('Model', 'Stacking Regressor')\n",
    "    mlflow.log_metric('Train - RMSE', rmse_train)\n",
    "    mlflow.log_metric('Test - RMSE', rmse_test)\n",
    "    mlflow.log_metric('Train - r2 score', r2_train)\n",
    "    mlflow.log_metric('Test - r2 score', r2_test)\n",
    "    mlflow.log_metric('Train - Adjusted r2 score', adj_r2_train)\n",
    "    mlflow.log_metric('Test - Adjusted r2 score', adj_r2_test)\n",
    "    mlflow.sklearn.log_model(pipeline, 'model',  signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that switching the final estimator to ElasticNet with alpha=0.7 and l1_ratio=0.3 gave us slightly better results. The Train $R^2$ score went up to 91.49%, and the Test $R^2$ score was 91.10%. For RMSE, we got 1822 on the Train set and 1860 on the Test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df.drop(columns=['PremiumPrice'])\n",
    "y_data = df['PremiumPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63344721, 0.65804126, 0.64586657, 0.74747812, 0.486833  ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = cross_val_score(estimator=LinearRegression(), \n",
    "                        X=X_data, \n",
    "                        y=y_data, \n",
    "                        scoring='r2', \n",
    "                        cv=5)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for alpha=0.02: [0.63344752 0.65803985 0.64587338 0.74747329 0.48683642]\n",
      "Score for alpha=0.06: [0.63344812 0.65803705 0.64588699 0.7474636  0.48684326]\n",
      "Score for alpha=0.3: [0.63345165 0.6580201  0.64596853 0.74740543 0.48688418]\n",
      "Score for alpha=0.58: [0.63345568 0.65800007 0.64606355 0.7473376  0.48693174]\n",
      "Score for alpha=0.7: [0.63345726 0.65799141 0.6461042  0.74730835 0.48695206]\n",
      "Score for alpha=0.9: [0.63345977 0.65797686 0.64617184 0.74725952 0.48698583]\n",
      "Score for alpha=1: [0.63346098 0.65796954 0.64620495 0.74723507 0.48700268]\n"
     ]
    }
   ],
   "source": [
    "l1_ratios = [0.02, 0.06, 0.3, 0.58, 0.7, 0.9, 1]\n",
    "\n",
    "for l1 in l1_ratios:\n",
    "    result = cross_val_score(estimator=Lasso(alpha=l1),\n",
    "                        X=X_data, \n",
    "                        y=y_data,\n",
    "                        scoring='r2', \n",
    "                        cv=5)\n",
    "\n",
    "    print(f'Score for alpha={l1}: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for alpha=0.1: [0.63341916 0.65799753 0.64602229 0.74732778 0.48702006]\n",
      "Score for alpha=0.3: [0.63335944 0.65790898 0.6463281  0.74702647 0.48738577]\n",
      "Score for alpha=0.5: [0.63329502 0.65781903 0.64662653 0.74672437 0.48774053]\n",
      "Score for alpha=0.7: [0.63322605 0.65772771 0.64691773 0.74642153 0.48808463]\n",
      "Score for alpha=0.05: [0.63343334 0.65801944 0.64594467 0.74740298 0.48692688]\n",
      "Score for alpha=0.004: [0.63344611 0.65803951 0.64587283 0.74747211 0.48684054]\n",
      "Score for alpha=0.08: [0.63342487 0.6580063  0.6459913  0.74735786 0.48698287]\n"
     ]
    }
   ],
   "source": [
    "l2_ratios = [0.1, 0.3, 0.5, 0.7, 0.05, 0.004, 0.08]\n",
    "\n",
    "for l2 in l2_ratios:\n",
    "    result = cross_val_score(estimator=Ridge(alpha=l2),\n",
    "                        X=X_data, \n",
    "                        y=y_data,\n",
    "                        scoring='r2', \n",
    "                        cv=5)\n",
    "\n",
    "    print(f'Score for alpha={l2}: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for l1=0.02, l2=0.1: [0.57609822 0.61801663 0.63983662 0.66516183 0.4753094 ]\n",
      "Score for l1=0.02, l2=0.3: [0.53450044 0.58517519 0.60958008 0.61376933 0.44724569]\n",
      "Score for l1=0.02, l2=0.5: [0.51916339 0.57168918 0.59615832 0.59461835 0.43629592]\n",
      "Score for l1=0.02, l2=0.7: [0.51104615 0.56425359 0.58867856 0.58443202 0.43046386]\n",
      "Score for l1=0.02, l2=0.05: [0.60093661 0.63531848 0.65209066 0.69607539 0.48948862]\n",
      "Score for l1=0.02, l2=0.004: [0.63209708 0.65654282 0.64989444 0.7427585  0.49146758]\n",
      "Score for l1=0.02, l2=0.08: [0.58466579 0.62415099 0.64468109 0.67573062 0.48054839]\n",
      "Score for l1=0.06, l2=0.1: [0.57772275 0.61919439 0.6407984  0.66716249 0.47632328]\n",
      "Score for l1=0.06, l2=0.3: [0.5359021  0.5863702  0.61075415 0.61551339 0.4482364 ]\n",
      "Score for l1=0.06, l2=0.5: [0.52027749 0.57269364 0.59716703 0.5960132  0.437096  ]\n",
      "Score for l1=0.06, l2=0.7: [0.51196403 0.56510448 0.58953559 0.58558592 0.43112295]\n",
      "Score for l1=0.06, l2=0.05: [0.60221893 0.63617575 0.6525524  0.69770876 0.49011231]\n",
      "Score for l1=0.06, l2=0.004: [0.63216901 0.65660906 0.64975886 0.74295292 0.49131955]\n",
      "Score for l1=0.06, l2=0.08: [0.58621994 0.62524334 0.64549731 0.67765372 0.48146673]\n",
      "Score for l1=0.3, l2=0.1: [0.58884638 0.62707442 0.6468308  0.68090881 0.48299173]\n",
      "Score for l1=0.3, l2=0.3: [0.54637871 0.59510239 0.61921966 0.62851605 0.45556726]\n",
      "Score for l1=0.3, l2=0.5: [0.52885241 0.58029432 0.60476137 0.60672817 0.44323086]\n",
      "Score for l1=0.3, l2=0.7: [0.51914499 0.5716713  0.59614607 0.59459316 0.4362836 ]\n",
      "Score for l1=0.3, l2=0.05: [0.6104002  0.64158963 0.65494092 0.70832436 0.49366   ]\n",
      "Score for l1=0.3, l2=0.004: [0.632574   0.65699842 0.64889799 0.74411742 0.49036483]\n",
      "Score for l1=0.3, l2=0.08: [0.59662872 0.63241437 0.65039599 0.69062802 0.48728907]\n",
      "Score for l1=0.58, l2=0.1: [0.60551979 0.63836646 0.65364382 0.701942   0.49164123]\n",
      "Score for l1=0.58, l2=0.3: [0.56614612 0.61062704 0.63355271 0.65290579 0.46891688]\n",
      "Score for l1=0.58, l2=0.5: [0.54635038 0.59507634 0.61920534 0.62847566 0.45554207]\n",
      "Score for l1=0.58, l2=0.7: [0.53445156 0.58512916 0.60955155 0.61370086 0.44720402]\n",
      "Score for l1=0.58, l2=0.05: [0.62076471 0.64840003 0.65599676 0.72265282 0.49640736]\n",
      "Score for l1=0.58, l2=0.004: [0.63298318 0.65743352 0.64778429 0.74546963 0.48909539]\n",
      "Score for l1=0.58, l2=0.08: [0.61140106 0.64224465 0.65515898 0.70965061 0.49403   ]\n",
      "Score for l1=0.7, l2=0.1: [0.61402486 0.64396415 0.65562761 0.71317635 0.49491434]\n",
      "Score for l1=0.7, l2=0.3: [0.57937283 0.62036766 0.64176745 0.66918413 0.47733457]\n",
      "Score for l1=0.7, l2=0.5: [0.55923053 0.60533362 0.62880865 0.64438295 0.46432637]\n",
      "Score for l1=0.7, l2=0.7: [0.54632208 0.59505029 0.61919054 0.62843508 0.45551687]\n",
      "Score for l1=0.7, l2=0.05: [0.62520748 0.65138229 0.6552594  0.7294505  0.49637713]\n",
      "Score for l1=0.7, l2=0.004: [0.63313534 0.65761297 0.64726825 0.74604621 0.4884954 ]\n",
      "Score for l1=0.7, l2=0.08: [0.61850396 0.64690543 0.65603226 0.7193894  0.49606176]\n",
      "Score for l1=0.9, l2=0.1: [0.62865728 0.65380337 0.65368496 0.73535603 0.49522678]\n",
      "Score for l1=0.9, l2=0.3: [0.61399523 0.64392901 0.6556441  0.71311607 0.49490298]\n",
      "Score for l1=0.9, l2=0.5: [0.60022767 0.63480664 0.65186347 0.69513864 0.48911917]\n",
      "Score for l1=0.9, l2=0.7: [0.58874134 0.62695282 0.6468204  0.68073797 0.48290007]\n",
      "Score for l1=0.9, l2=0.05: [0.63157968 0.65608199 0.65076651 0.74143253 0.49239433]\n",
      "Score for l1=0.9, l2=0.004: [0.63335474 0.65790175 0.64635285 0.74700205 0.48741442]\n",
      "Score for l1=0.9, l2=0.08: [0.62991338 0.65474091 0.65270692 0.73777677 0.49434199]\n",
      "Score for l1=1, l2=0.1: [0.63344875 0.65803424 0.64590061 0.74745397 0.48685009]\n",
      "Score for l1=1, l2=0.3: [0.63345165 0.6580201  0.64596853 0.74740543 0.48688418]\n",
      "Score for l1=1, l2=0.5: [0.63345461 0.65800582 0.64603642 0.74735708 0.48691817]\n",
      "Score for l1=1, l2=0.7: [0.63345726 0.65799141 0.6461042  0.74730835 0.48695206]\n",
      "Score for l1=1, l2=0.05: [0.63344797 0.65803775 0.64588359 0.74746602 0.48684155]\n",
      "Score for l1=1, l2=0.004: [0.63344727 0.65804098 0.64586793 0.74747716 0.48683369]\n",
      "Score for l1=1, l2=0.08: [0.63344842 0.65803564 0.6458938  0.74745875 0.48684668]\n"
     ]
    }
   ],
   "source": [
    "for l1 in l1_ratios:\n",
    "    for l2 in l2_ratios:\n",
    "        result = cross_val_score(estimator=ElasticNet(alpha=l2, l1_ratio=l1),\n",
    "                        X=X_data, \n",
    "                        y=y_data,\n",
    "                        scoring='r2', \n",
    "                        cv=5)\n",
    "\n",
    "        print(f'Score for l1={l1}, l2={l2}: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use some of the tried and test model with better performance from 05-1_PremiumPrice_Prediction_RawData_StratifiedAge.ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.30188489, 0.35745621, 0.30556989, 0.29974699, 0.27579904]),\n",
       " 'score_time': array([0.00221992, 0.00156188, 0.00156879, 0.00168586, 0.0013938 ]),\n",
       " 'test_r2': array([0.86348225, 0.74466964, 0.78499819, 0.91582313, 0.67049145]),\n",
       " 'train_r2': array([0.90250353, 0.93931496, 0.93031811, 0.90425578, 0.94130358]),\n",
       " 'test_neg_root_mean_squared_error': array([-2301.42502118, -3092.33720115, -2655.43871953, -1862.08977497,\n",
       "        -3795.20144993]),\n",
       " 'train_neg_root_mean_squared_error': array([-1951.10001746, -1543.41033726, -1680.26550631, -1917.55453916,\n",
       "        -1487.86070263])}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=110, max_depth=5, learning_rate=0.1, loss='huber')\n",
    "\n",
    "cv_results = cross_validate(model, X_data, y_data, cv=5, return_train_score=True, scoring=('r2', 'neg_root_mean_squared_error'))\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.06442213, 0.06643605, 0.06436992, 0.11081314, 0.06693983]),\n",
       " 'score_time': array([0.01362371, 0.01353192, 0.0149622 , 0.01379681, 0.01405215]),\n",
       " 'test_r2': array([0.84467857, 0.76986452, 0.80831664, 0.90018582, 0.69550379]),\n",
       " 'train_r2': array([0.93390069, 0.94673158, 0.93764069, 0.9258052 , 0.94541225]),\n",
       " 'test_neg_root_mean_squared_error': array([-2454.81043894, -2935.80636097, -2507.30653589, -2027.68435875,\n",
       "        -3648.31592184]),\n",
       " 'train_neg_root_mean_squared_error': array([-1606.51039528, -1446.02395593, -1589.52959908, -1688.02226384,\n",
       "        -1434.8418505 ])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, max_depth=7, n_jobs=-1)\n",
    "\n",
    "cv_results = cross_validate(model, X_data, y_data, cv=5, return_train_score=True, scoring=('r2', 'neg_root_mean_squared_error'))\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.06813812, 0.05330324, 0.0564642 , 0.05135369, 0.06240892]),\n",
       " 'score_time': array([0.00274086, 0.00247192, 0.00262403, 0.00224304, 0.00277305]),\n",
       " 'test_r2': array([0.80945683, 0.78494561, 0.79003209, 0.88181549, 0.66385293]),\n",
       " 'train_r2': array([0.92571282, 0.93614727, 0.93406212, 0.92825586, 0.9438473 ]),\n",
       " 'test_neg_root_mean_squared_error': array([-2718.93601231, -2837.9828658 , -2624.16788679, -2206.40126467,\n",
       "        -3833.24103127]),\n",
       " 'train_neg_root_mean_squared_error': array([-1703.10688769, -1583.17983665, -1634.50176858, -1659.91078874,\n",
       "        -1455.26367136])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(max_depth=6, n_estimators=90, learning_rate=0.03, reg_alpha=0.5, reg_lambda=0.7)\n",
    "\n",
    "cv_results = cross_validate(model, X_data, y_data, cv=5, return_train_score=True, scoring=('r2', 'neg_root_mean_squared_error'))\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** Train Result **********\n",
      "RMSE: 1608.663764075114\n",
      "R2 Score: 0.9336699595751619\n",
      "Adjusted R2 Score: 0.9328162911012257\n",
      "\n",
      "****************** Test Result **********\n",
      "RMSE: 1877.1003073691975\n",
      "R2 Score: 0.909381127827578\n",
      "Adjusted R2 Score: 0.9045351988344004\n"
     ]
    }
   ],
   "source": [
    "base_learner = [\n",
    "    ('gb1', GradientBoostingRegressor(n_estimators=110, max_depth=5, learning_rate=0.1, loss='huber')),\n",
    "    ('gb2', GradientBoostingRegressor(n_estimators=120, max_depth=5, learning_rate=0.1, loss='huber')),\n",
    "    ('rd1', RandomForestRegressor(n_estimators=100, max_depth=7, n_jobs=-1)),\n",
    "    ('rd2', RandomForestRegressor(n_estimators=90, max_depth=7, n_jobs=-1)),\n",
    "    ('xg1', xgb.XGBRegressor(max_depth=6, n_estimators=90, learning_rate=0.03, reg_alpha=0.5, reg_lambda=0.7)),\n",
    "    ('xg2', xgb.XGBRegressor(max_depth=6, n_estimators=80, learning_rate=0.04, reg_alpha=0.1, reg_lambda=0.7))\n",
    "]\n",
    "\n",
    "final_estimator = LinearRegression()\n",
    "\n",
    "model = StackingRegressor(estimators=base_learner, final_estimator=final_estimator)\n",
    "    \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "rmse_train = rmse(y_train, y_train_pred)\n",
    "rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "r2_train, adj_r2_train = score(y_train, y_train_pred, X_train.shape[0], X_train.shape[1])\n",
    "r2_test, adj_r2_test = score(y_test, y_test_pred, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "print('*'*18, 'Train Result', '*'*10)\n",
    "print(f'RMSE: {rmse_train}')\n",
    "print(f'R2 Score: {r2_train}')\n",
    "print(f'Adjusted R2 Score: {adj_r2_train}')\n",
    "print('')\n",
    "\n",
    "print('*'*18, 'Test Result', '*'*10)\n",
    "print(f'RMSE: {rmse_test}')\n",
    "print(f'R2 Score: {r2_test}')\n",
    "print(f'Adjusted R2 Score: {adj_r2_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Individually these models are not performing any better, However, the stacking regressor gave us better performance and hence can be used for final model creation.\n",
    "- This can also be observed in the ML Flow run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
